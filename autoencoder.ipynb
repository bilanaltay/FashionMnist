{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image , ImageOps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fashionMnist = datasets.FashionMNIST(root = \"data\",train = True, transform= ToTensor(),download=True)\n",
    "test_fashionMnist = datasets.FashionMNIST(root = \"data\",train = False, transform= ToTensor(), download= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fashionMnist[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, fashionMnist):\n",
    "        self.fashionMnist = fashionMnist\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fashionMnist)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.fashionMnist[index]\n",
    "        return x[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_fashionMnist)\n",
    "test_dataset = MyDataset(test_fashionMnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size= 32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,encoding_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),            \n",
    "            nn.Linear(128, encoding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,encoding_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 784)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encoding_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.encoder = Encoder(encoding_dim)\n",
    "        self.decoder = Decoder(encoding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    output = model(batch)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 784])\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/3, loss = 0.028021\n",
      "epoch : 2/3, loss = 0.017893\n",
      "epoch : 3/3, loss = 0.015757\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs= 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for batch_features in train_dataloader:\n",
    "        #batch leri yeniden boyutlandırma\n",
    "        batch_features = batch_features.view(-1, 784)\n",
    "        #Pytorch her geriye geçişte gradyanları biriktirir, bu yüzden gradyanlar sıfırlanır\n",
    "        optimizer.zero_grad()\n",
    "        #train dataloaderları modele sokuyoruz, yeniden yapılandırma\n",
    "        train_outputs = model(batch_features)\n",
    "        #yeniden yapılandırdığımız verilerle batch dataloaderları karşılaştırarak bir kayıp elde edilir\n",
    "        train_loss = criterion(train_outputs, batch_features)\n",
    "        #kaybın gradyanı hesaplanır\n",
    "        train_loss.backward()\n",
    "        #Optimizasyon algoritmasını (Adam) kullanarak geçerli gradyana göre parametreler güncellenir\n",
    "        optimizer.step()\n",
    "        #mini-batch training loss epoch lossa eklenir\n",
    "        loss += train_loss.item()\n",
    "    \n",
    "    #Bir epoch tamamlandığında, toplam kaybı train dataloader sayısına bölerek, epoch train loss hesaplanır\n",
    "    loss = loss / len(train_dataloader)\n",
    "\n",
    "    print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = train_outputs[1].detach().numpy().reshape(28, 28)\n",
    "image = (image * 255).astype(np.uint8)\n",
    "image = Image.fromarray(image)\n",
    "image.save(\"fashion_mnist_project/resim.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss = 0.015171\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "loss2 = 0\n",
    "\n",
    "with torch.no_grad(): #gradyanların bellekte tutulması engellenir\n",
    "    for batch_features in test_dataloader:\n",
    "        batch_features = batch_features.view(-1, 784)\n",
    "        test_outputs = model(batch_features)\n",
    "        test_loss = criterion(test_outputs, batch_features)\n",
    "        loss2 += test_loss.item()\n",
    "\n",
    "loss2 = loss2 / len(test_dataloader)\n",
    "print(\"Test loss = {:.6f}\".format(loss2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = test_outputs[1].detach().numpy().reshape(28, 28)\n",
    "image = (image * 255).astype(np.uint8)\n",
    "image = Image.fromarray(image)\n",
    "image.save(\"fashion_mnist_project/resim1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import  seaborn as sbn\n",
    "#sbn.lineplot(x=range(len(train_outputs)),y=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=Autoencoder\n",
       "  (flatten): RecursiveScriptModule(original_name=Flatten)\n",
       "  (encoder): RecursiveScriptModule(\n",
       "    original_name=Encoder\n",
       "    (encoder): RecursiveScriptModule(\n",
       "      original_name=Sequential\n",
       "      (0): RecursiveScriptModule(original_name=Linear)\n",
       "      (1): RecursiveScriptModule(original_name=ReLU)\n",
       "      (2): RecursiveScriptModule(original_name=Linear)\n",
       "      (3): RecursiveScriptModule(original_name=ReLU)\n",
       "      (4): RecursiveScriptModule(original_name=Linear)\n",
       "      (5): RecursiveScriptModule(original_name=ReLU)\n",
       "      (6): RecursiveScriptModule(original_name=Linear)\n",
       "    )\n",
       "  )\n",
       "  (decoder): RecursiveScriptModule(\n",
       "    original_name=Decoder\n",
       "    (decoder): RecursiveScriptModule(\n",
       "      original_name=Sequential\n",
       "      (0): RecursiveScriptModule(original_name=Linear)\n",
       "      (1): RecursiveScriptModule(original_name=ReLU)\n",
       "      (2): RecursiveScriptModule(original_name=Linear)\n",
       "      (3): RecursiveScriptModule(original_name=ReLU)\n",
       "      (4): RecursiveScriptModule(original_name=Linear)\n",
       "      (5): RecursiveScriptModule(original_name=ReLU)\n",
       "      (6): RecursiveScriptModule(original_name=Linear)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    pass \n",
    "if __name__==\"__main__\":\n",
    "    train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d03b610c6d351ee5338ff0cf32b427b9fc317b1b7acd9bd59ebc295c864f800"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
